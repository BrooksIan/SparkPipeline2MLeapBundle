{"paragraphs":[{"text":"%md\n\n## Data Science In Apache Spark\n### Spark Pipeline ID/IDF Model\n### Export to MLeap Bundle\n\n**Language**: Scala\n**Requirements**: \n- [HDP 2.6.X]\n- Spark 2.x\n\n**Author**: Ian Brooks\n**Follow**: [LinkedIn - Ian Brooks PhD] (https://www.linkedin.com/in/ianrbrooksphd/)\n**GitHub**: [Github] (https://github.com/BrooksIan/SparkPipeline2MLeapBundle)\n**MLeap**: [MLeap Spark] (http://mleap-docs.combust.ml/spark/) [MLeap GitHub](https://github.com/combust/mleap)\n\n![MLeap](http://mleap-docs.combust.ml/assets/images/logo.png \"MLeap\")","user":"admin","dateUpdated":"2018-12-20T11:04:18-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804769_-1500268961","id":"20180802-165542_1891013089","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T11:04:18-0800","dateFinished":"2018-12-20T11:04:18-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:30576","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Data Science In Apache Spark</h2>\n<h3>Spark Pipeline ID/IDF Model</h3>\n<h3>Export to MLeap Bundle</h3>\n<p><strong>Language</strong>: Scala\n<br  /><strong>Requirements</strong>:</p>\n<ul>\n<li>[HDP 2.6.X]</li>\n<li>Spark 2.x</li>\n</ul>\n<p><strong>Author</strong>: Ian Brooks\n<br  /><strong>Follow</strong>: <a href=\"https://www.linkedin.com/in/ianrbrooksphd/\">LinkedIn - Ian Brooks PhD</a>\n<br  /><strong>GitHub</strong>: <a href=\"https://github.com/BrooksIan/SparkPipeline2MLeapBundle\">Github</a>\n<br  /><strong>MLeap</strong>: <a href=\"http://mleap-docs.combust.ml/spark/\">MLeap Spark</a> <a href=\"https://github.com/combust/mleap\">MLeap GitHub</a></p>\n<p><img src=\"http://mleap-docs.combust.ml/assets/images/logo.png\" alt=\"MLeap\" title=\"MLeap\" /></p>\n"}]}},{"title":"Load Data From GitHub","text":"%sh\n\n# Download Data from Github\nwget https://raw.githubusercontent.com/BrooksIan/SparkPipeline2MLeapBundle/master/sbir-search-results1.json -O /tmp/sbir-search-results1.json\nwget https://raw.githubusercontent.com/BrooksIan/SparkPipeline2MLeapBundle/master/sbir-search-results2.json -O /tmp/sbir-search-results2.json\n\n\n# Make HDFS Directory and Load CSV files into HDFS\nhadoop fs -mkdir /tmp/\nhadoop fs -put /tmp/sbir-search-results1.json /tmp/sbir-search-results1.json\nhadoop fs -put /tmp/sbir-search-results2.json /tmp/sbir-search-results2.json\n\nhadoop fs -ls /tmp/sbir*\n","user":"admin","dateUpdated":"2018-12-20T11:02:59-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326967441_1359983366","id":"20181220-092927_966441144","dateCreated":"2018-12-20T09:29:27-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30577"},{"title":"Load Dependency - MLeap Spark Libs","text":"%dep\n\nz.load(\"ml.combust.mleap:mleap-spark_2.11:0.13.0\")\n","user":"admin","dateUpdated":"2018-12-20T09:30:44-0800","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804779_-1502577455","id":"20181218-133214_69707546","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T09:30:44-0800","dateFinished":"2018-12-20T09:30:54-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30578"},{"title":"Load Dependency - MLeap Spark Entension","text":"%dep\n\nz.load(\"ml.combust.mleap:mleap-spark-extension_2.11:0.13.0\")\n","dateUpdated":"2018-12-20T09:26:44-0800","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"title":true,"results":{},"enabled":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804779_-1502577455","id":"20181218-133302_1394695092","dateCreated":"2018-12-20T09:26:44-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30579"},{"title":"Initialize Spark Context","text":"%spark2\n\nimport org.apache.spark.sql.SparkSession\nval spark: SparkSession = SparkSession.builder\n  .appName(\"SparkPipelineMLeap\")  // optional and will be autogenerated if not specified\n  .master(\"local[*]\")               // avoid hardcoding the deployment environment\n  .enableHiveSupport()              // self-explanatory, isn't it?\n  .config(\"spark.sql.warehouse.dir\", \"target/spark-warehouse\")\n  .getOrCreate\n\nspark.version\n","user":"admin","dateUpdated":"2018-12-20T09:31:42-0800","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804780_-1504501199","id":"20180228-182438_444603187","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T09:31:42-0800","dateFinished":"2018-12-20T09:32:04-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30580"},{"title":"Load Data From File","text":"import org.apache.spark.sql.types._\nimport org.apache.spark.sql.DataFrame\nimport scala.collection.mutable.ListBuffer\n\n//Create a data frame from CSV File \nval df_WholeSetRaw = sqlContext.read.option(\"multiline\", \"true\").json(\"/tmp/sbir-search-results*.json\")\n\ndf_WholeSetRaw.cache()\n\n//Create Table from DataFrame\n//df_WholeSetRaw.createOrReplaceTempView(\"SBIR2018\")\n\n//Display resulting Infered schema \ndf_WholeSetRaw.printSchema()\n\n//df_WholeSetRaw.take(1)\n\nval df_abstracts = df_WholeSetRaw.select(\"abstract\")","user":"admin","dateUpdated":"2018-12-20T10:35:21-0800","config":{"editorSetting":{"language":"scala","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804781_-1504885948","id":"20180228-182512_1457175841","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T09:52:44-0800","dateFinished":"2018-12-20T09:52:48-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30581"},{"title":"Configure and Test Pipeline Stages","text":"%spark2\n\nimport org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer, RegexTokenizer, CountVectorizer, CountVectorizerModel}\nimport org.apache.spark.ml.classification.LogisticRegression\n\nval TFtokenizer = new RegexTokenizer()\n      .setInputCol(\"abstract\")\n      .setOutputCol(\"words\")\n      .setPattern(\"\\\\W+\")\n      .setGaps(true)\n    \nval TFwordsData = TFtokenizer.transform(df_WholeSetRaw)\n\nval hashingTF = new HashingTF()\n    .setInputCol(\"words\")\n    .setOutputCol(\"rawFeatures\")\n    .setNumFeatures(1000)\n\n\n//val TFfeaturizedData = cvModel.transform(TFwordsData)\n\nval TFfeaturizedData = hashingTF.transform(TFwordsData)\n\nval TFIDF = new IDF()\n    .setInputCol(\"rawFeatures\")\n    .setOutputCol(\"features\")\n\nval idfModel = TFIDF.fit(TFfeaturizedData)\n\nval rescaledData = idfModel.transform(TFfeaturizedData)\n\nrescaledData.select(\"features\").show()","user":"admin","dateUpdated":"2018-12-20T10:43:25-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545327199000_-1057273024","id":"20181220-093319_828690239","dateCreated":"2018-12-20T09:33:19-0800","dateStarted":"2018-12-20T10:43:25-0800","dateFinished":"2018-12-20T10:43:34-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30582"},{"title":"Build Spark Pipeline Model","text":"%spark2\n\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.linalg.Vector\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.StructType\n\n\nval pipeline = new Pipeline()\n  .setStages(Array(TFtokenizer, hashingTF, TFIDF))\n\nval PipeLineModel = pipeline.fit(df_abstracts)\n\n//Save Pipeline to Disk (Optional)\nPipeLineModel.write.overwrite().save(\"/tmp/spark-pipelineModel-tfidf\")\n\nval schema = df_abstracts.schema","user":"admin","dateUpdated":"2018-12-20T10:43:38-0800","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804783_-1504116450","id":"20180726-002543_1016279965","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T10:43:38-0800","dateFinished":"2018-12-20T10:43:46-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30583"},{"title":"Export Spark Pipeline Model To MLeap Bundle - Zip & Directory","text":"%spark2\n\nimport ml.combust.bundle.BundleFile\nimport ml.combust.bundle.serializer.SerializationFormat\nimport org.apache.spark.ml.mleap.SparkUtil\nimport ml.combust.mleap.spark.SparkSupport._\nimport org.apache.spark.ml.bundle._\nimport resource._\n\n\n  //Init Spark Bundle Context to MLeap\n  val sbc = SparkBundleContext().withDataset(PipeLineModel.transform(df_WholeSetRaw))\n\n // Serialize Pipeline to Zip\n // *** This will fail if the file exist ***\n  (for(bundlefile <- managed(BundleFile(\"jar:file:/tmp/MLeapModels/spark-nlp-tfidf-pipeline.zip\"))) yield {\n    PipeLineModel.writeBundle.save(bundlefile)(sbc).get\n  }).tried.get\n\n  //Serialize Pipeline to Directory\n  for(bundle <- managed(BundleFile(\"file:/tmp/MLeapModels/spark-nlp-tfidf-pipeline-dir\"))) {\n    PipeLineModel.writeBundle.format(SerializationFormat.Json).save(bundle)\n  }\n","user":"admin","dateUpdated":"2018-12-20T10:46:38-0800","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804784_-1493728230","id":"20180726-003539_171431978","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T10:46:21-0800","dateFinished":"2018-12-20T10:46:28-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30584"},{"title":"Validate MLeap Model Bundles Are On File System","text":"%sh\n\nls -l /tmp/MLeapModels/\n\nls -l /tmp/MLeapModels/spark-nlp-tfidf-pipeline-dir/root/","user":"admin","dateUpdated":"2018-12-20T10:51:08-0800","config":{"editorSetting":{"language":"sh","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sh","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804784_-1493728230","id":"20181219-094027_870611183","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T10:51:08-0800","dateFinished":"2018-12-20T10:51:08-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30585"},{"title":"Import Spark Pipeline From MLeap Bundle - Zip","text":"%spark2\n\nimport ml.combust.bundle.BundleFile\nimport ml.combust.mleap.runtime.MleapSupport._\nimport resource._\n\n// Deserialize a zip bundle\nval bundle = (for(bundleFile <- managed(BundleFile(\"jar:file:/tmp/MLeapModels/spark-nlp-tfidf-pipeline.zip\"))) yield {\n  bundleFile.loadMleapBundle().get\n}).opt.get\n\n\n// Deserialize a directory bundle\n//val dirBundle = (for(bundleDir <- managed(BundleFile(\"file:/tmp/MLeapModels/park-nlp-tfidf-pipeline-dir/\"))) yield {\n//  bundleDir.loadSparkBundle().get\n//}).opt.get\n","user":"admin","dateUpdated":"2018-12-20T10:50:24-0800","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804785_-1494112979","id":"20181219-074408_1998429579","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T10:46:42-0800","dateFinished":"2018-12-20T10:46:46-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30586"},{"title":"Define Leap Frame Scema and Build Test Leap Frame","text":"%spark2\nimport ml.combust.mleap.runtime._\nimport ml.combust.mleap.runtime.frame.{DefaultLeapFrame, Row}\nimport ml.combust.mleap.core.types._\n\n// create a simple LeapFrame to transform\n\n// Create a schema. Returned as a Try monad to ensure that there\n// Are no duplicate field names\nval schemaLF: ml.combust.mleap.core.types.StructType = ml.combust.mleap.core.types.StructType(StructField(\"abstract\", ScalarType.String)).get\n  \n// Create a dataset to contain all of our values\n// This dataset has two rows\nval dataset = Seq(Row(\"Hello, MLeap this my abstract\"),\n                  Row(\"Another abstact\"))\n  \n// Create a LeapFrame from the schema and dataset\nval leapFrame = DefaultLeapFrame(schemaLF,dataset)\n","user":"admin","dateUpdated":"2018-12-20T10:46:56-0800","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545326804786_-1492958732","id":"20181219-080708_1932583450","dateCreated":"2018-12-20T09:26:44-0800","dateStarted":"2018-12-20T10:46:56-0800","dateFinished":"2018-12-20T10:47:01-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30587"},{"title":"Run Test Leap Frame on Pipeline","text":"%spark2\n\n// Retrieve pipeline model\nval mleapPipeline = bundle.root\n\n// Transform on new Leap Frame\nval resultLeapFrame =  mleapPipeline.transform(leapFrame).get","user":"admin","dateUpdated":"2018-12-20T10:47:20-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545329034841_1077533869","id":"20181220-100354_588578743","dateCreated":"2018-12-20T10:03:54-0800","dateStarted":"2018-12-20T10:47:20-0800","dateFinished":"2018-12-20T10:47:22-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30588"},{"title":"Review Pineline Results","text":"%spark2\n\n//  Convert Leap Frame to Rows\nval dataRows = resultLeapFrame.dataset\n\n// Review results from row 1\nval abstract1 = dataRows(0)(0)\nval features1 = dataRows(0)(2)\n\n//Review results from row 2\nval abstract2 = dataRows(1)(0)\nval features2 = dataRows(1)(2)\n","user":"admin","dateUpdated":"2018-12-20T10:47:26-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545328747754_-47485595","id":"20181220-095907_1316133718","dateCreated":"2018-12-20T09:59:07-0800","dateStarted":"2018-12-20T10:47:26-0800","dateFinished":"2018-12-20T10:47:31-0800","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30589"},{"text":"%spark2\n","user":"admin","dateUpdated":"2018-12-20T10:48:08-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1545331688285_880355253","id":"20181220-104808_1829257522","dateCreated":"2018-12-20T10:48:08-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:30590"}],"name":"MLeap - Spark Pipeline TF/IDF","id":"2DY2SJ3EV","angularObjects":{"2CHS8UYQQ:shared_process":[],"2CKX6DGQZ:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CK8A9MEG:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CKX8WPU1:shared_process":[],"2CKAY1A8Y:shared_process":[],"2CKEKWY8Z:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}